version: '3.7'

services:
  master:
    hostname: master
    container_name: master
    image: jungfrau70/ubuntu18.04:de-cluster.3
    command: >
      sh -c "service ssh start &&
             tail -f /dev/null"
    restart: always
    networks:
      netgroup:
        ipv4_address: 172.18.0.21
    ports:
      - "4040:4040"
      - "9090:8080"
      - "8088:8088"
      - "8888:8888"
      - "7077:7077"
      - "18040:18040"
    volumes:
      # Just specify a path and let the Engine create a volume
      - /sys/fs/cgroup:/sys/fs/cgroup:ro
      - ~/.ssh:/root/.ssh:ro
      - ./spark-apps:/opt/spark-apps
      - ./spark-data:/opt/spark-data
      - ../../dags:/home/jovyan/dags
    privileged: true
    deploy:
      resources:
        limits:
          memory: 4g
        reservations:
          memory: 2g
    cap_add:
      - NET_ADMIN
    env_file:
      - cluster.env

  worker1:
    hostname: worker1
    container_name: worker1
    image: jungfrau70/ubuntu18.04:de-cluster.3
    command: >
      sh -c "service ssh start &&
             tail -f /dev/null"
    restart: always
    networks:
      netgroup:
        ipv4_address: 172.18.0.31
    depends_on:
      - master
    volumes:
      # Just specify a path and let the Engine create a volume
      - /sys/fs/cgroup:/sys/fs/cgroup:ro
      - ./spark-apps:/opt/spark-apps
      - ./spark-data:/opt/spark-data
    privileged: true
    deploy:
      resources:
        limits:
          memory: 4g
        reservations:
          memory: 2g
    cap_add:
      - NET_ADMIN
    env_file:
      - cluster.env

  worker2:
    hostname: worker2
    container_name: worker2
    image: jungfrau70/ubuntu18.04:de-cluster.3
    command: >
      sh -c "service ssh start &&
             tail -f /dev/null"
    restart: always
    networks:
      netgroup:
        ipv4_address: 172.18.0.32
    depends_on:
      - master
    volumes:
      # Just specify a path and let the Engine create a volume
      - /sys/fs/cgroup:/sys/fs/cgroup:ro
      - ./spark-apps:/opt/spark-apps
      - ./spark-data:/opt/spark-data
    privileged: true
    deploy:
      resources:
        limits:
          memory: 4g
        reservations:
          memory: 2g
    cap_add:
      - NET_ADMIN
    env_file:
      - cluster.env

  hive-postgres:
    hostname: hive-postgres
    container_name: hive-postgres
    image: postgres:9.6.24 # latest
    restart: always
    networks:
      netgroup:
        ipv4_address: 172.18.0.11
    ports:
    - "6432:5432"
    volumes:
      # Just specify a path and let the Engine create a volume
      - ./db.sql:/docker-entrypoint-initdb.d/db.sql
      - ./postgres-data:/var/lib/postgresql/data
    privileged: true
    cap_add:
      - NET_ADMIN
    env_file:
      - postgres.env

networks:
  netgroup:
    name: netgroup
    driver: bridge
    attachable: true
    ipam:
      config:
        - subnet: 172.18.0.0/16
          gateway: 172.18.0.1
